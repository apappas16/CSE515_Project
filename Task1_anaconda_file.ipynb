{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the data directory path: Data/\n",
      "Enter the window length: 3\n",
      "Enter the shift length: 3\n",
      "Enter the resolution: 3\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "from scipy.integrate import quad\n",
    "\n",
    "\n",
    "def calcAvgSensorValue(sensorValues):\n",
    "    avg = sum(sensorValues) / len(sensorValues)\n",
    "    avg = round(avg, 9)\n",
    "    return avg\n",
    "\n",
    "\n",
    "def calcStdDev(sensorValues, meanVal):\n",
    "    sd = []\n",
    "    for num in sensorValues:\n",
    "        result = num - meanVal\n",
    "        result = result * result\n",
    "        sd.append(result)\n",
    "    return calcAvgSensorValue(sd)\n",
    "\n",
    "\n",
    "def normalize(sensorValues):\n",
    "    normalized_sensor = []\n",
    "    for val in sensorValues:\n",
    "        val = float(val)\n",
    "        normalized = 2 * ((val - min(sensorValues)) / (max(sensorValues) - min(sensorValues))) - 1\n",
    "        normalized_sensor.append(normalized)\n",
    "    return normalized_sensor\n",
    "\n",
    "\n",
    "def integral(i):\n",
    "    return getGaussianVal(i, 0, 0.25)\n",
    "\n",
    "\n",
    "def getGaussianVal(i, avg, sd):\n",
    "    i = float(i - avg) / sd\n",
    "    gauss = math.exp(-i * i / 2.0) / math.sqrt(2.0 * math.pi) / sd\n",
    "    return gauss\n",
    "\n",
    "\n",
    "def determineBands():\n",
    "    numBands = r * 2\n",
    "    bandList = []\n",
    "    bandStart = -1\n",
    "    for i in range(1, numBands):\n",
    "        integral1, e = quad(integral, (i - r - 1) / r, (i - r) / r)\n",
    "        integral2, e = quad(integral, -1, 1)\n",
    "        length_i = 2 * (integral1 / integral2)\n",
    "        band = bandStart + length_i\n",
    "        bandList.append(band)\n",
    "        bandStart = band\n",
    "    bandList.append(1.0)\n",
    "    return bandList\n",
    "\n",
    "\n",
    "def quantize(values, bandList):\n",
    "    quantized = \"\"\n",
    "    for i in range(len(values)):\n",
    "        bound = -1\n",
    "        for band in bandList:\n",
    "            if band >= values[i] > bound:\n",
    "                quantized += str(bandList.index(band) + 1)\n",
    "                break\n",
    "            else:\n",
    "                bound = band\n",
    "    return quantized\n",
    "\n",
    "\n",
    "def getWords():\n",
    "    wordList = []\n",
    "    i = 0\n",
    "    while (i + w - 1) < len(quantizedSensor):\n",
    "        word = quantizedSensor[i:i + w]\n",
    "        wordList.append(word)\n",
    "        i += s\n",
    "    return wordList\n",
    "\n",
    "\n",
    "def addToUniqueDict(word_tuple):\n",
    "    inList = False\n",
    "    for word in unique_dict:\n",
    "        if word == word_tuple:\n",
    "            inList = True\n",
    "            break\n",
    "    if not inList:\n",
    "        unique_dict.append(word_tuple)\n",
    "\n",
    "\n",
    "def calcAvgQuanAmp():\n",
    "    avgQuanAmpList = []\n",
    "    normWord = []\n",
    "    i = 0\n",
    "    while (i + w - 1) < len(normSensorVals):\n",
    "        word = normSensorVals[i:i + w]\n",
    "        normWord.append(word)\n",
    "        i += s\n",
    "\n",
    "    for word in normWord:\n",
    "        avgAmp = sum(word) / len(word)\n",
    "        avgQuanAmpList.append(avgAmp)\n",
    "\n",
    "    return avgQuanAmpList\n",
    "\n",
    "\n",
    "def getWordsFromFile(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        words = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            row = line.split(\" - [\")  # list of all words as they occur in the file\n",
    "            if len(row) > 1:\n",
    "                words.append(row[1])\n",
    "        f.close()\n",
    "    return formatWordsFromFile(words)\n",
    "\n",
    "\n",
    "def formatWordsFromFile(tempList):\n",
    "    allWords = []\n",
    "    for sensorWords in tempList:\n",
    "        sensorWords = sensorWords.replace(\"]\", \"\")\n",
    "        sensorWords = sensorWords.replace(\"'\", \"\")\n",
    "        wrd = sensorWords.split(\", \")\n",
    "        allWords.append(wrd)\n",
    "    return allWords\n",
    "\n",
    "\n",
    "def getUniqueWordsInGesture(allWordsInGesture):\n",
    "    uniqueWords = []\n",
    "    for i in range(len(allWordsInGesture)):  # i is each sensor in the gesture\n",
    "        for word in allWordsInGesture[i]:\n",
    "            uniqueWord = (direct, i+1, word)\n",
    "            if uniqueWord not in uniqueWords:\n",
    "                uniqueWords.append(uniqueWord)\n",
    "    return uniqueWords\n",
    "\n",
    "\n",
    "def calcTfValue(wordTuple, allWordsInFile):\n",
    "    totalWords = len(allWordsInFile[0]) * 20\n",
    "    num_occurs = 0\n",
    "    for sensor in range(len(allWordsInFile)):\n",
    "        for wrd in allWordsInFile[sensor]:\n",
    "            if wrd == wordTuple[2] and (sensor+1) == wordTuple[1]:\n",
    "                num_occurs += 1\n",
    "    value = num_occurs / totalWords\n",
    "    return value\n",
    "\n",
    "\n",
    "def calcIdfValue(wordTuple, direct):\n",
    "    numObjs = 60\n",
    "    numObjsWithWord = 1\n",
    "    sensorId = wordTuple[1]\n",
    "\n",
    "    for file in os.listdir(directory + direct):\n",
    "        if file != gestureFile and file.endswith(\".wrd\"):\n",
    "            file = directory + direct + \"/\" + file\n",
    "            gestFileWords = getWordsFromFile(file)\n",
    "            if word_tuple[2] in gestFileWords[sensorId-1]:\n",
    "                numObjsWithWord += 1\n",
    "                break\n",
    "\n",
    "    value = math.log(numObjs / numObjsWithWord)\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # GLOBAL VARIABLES:\n",
    "    unique_dict = []  # stores list of all unique words found\n",
    "    gesture_dict = []  # stores list of all words found across all files\n",
    "\n",
    "    # TASK 0\n",
    "    # TASK 0A\n",
    "    directory = input(\"Enter the data directory path: \")\n",
    "    w = input(\"Enter the window length: \")\n",
    "    s = input(\"Enter the shift length: \")\n",
    "    r = input(\"Enter the resolution: \")\n",
    "\n",
    "    w = int(w)\n",
    "    s = int(s)\n",
    "    r = int(r)\n",
    "\n",
    "    # for each data file create a .wrd file containing the following:\n",
    "    for direct in os.listdir(directory):\n",
    "        # for each csv file in X,Y,W,Z:\n",
    "        for filename in os.listdir(directory + direct):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                bands = determineBands()\n",
    "\n",
    "                # generate .wrd file\n",
    "                wrdFile = open(str(directory) + str(direct) + \"/\" + str(filename) + \".wrd\", \"w\")\n",
    "\n",
    "                sensor_id = 1\n",
    "                csvFile = open(str(directory) + str(direct) + \"/\" + filename, \"r\")\n",
    "                reader = csv.reader(csvFile, delimiter=',')\n",
    "                # for each sensor sj in file\n",
    "                for sensor in reader:\n",
    "                    # output component ID, c in output file\n",
    "                    wrdFile.write(str(direct) + \", \")\n",
    "\n",
    "                    # write sensorID to wrd file\n",
    "                    wrdFile.write(str(sensor_id) + \", \")\n",
    "\n",
    "                    # compute and output average amplitude, avgij of the values\n",
    "                    sensorVals = list(sensor)\n",
    "                    sensorVals = [float(i) for i in sensorVals]\n",
    "                    sensorAvg = calcAvgSensorValue(sensorVals)\n",
    "                    wrdFile.write(str(sensorAvg) + \", \")\n",
    "\n",
    "                    # compute and output standard deviations stdij of the values\n",
    "                    stdDev = calcStdDev(sensorVals, sensorAvg)\n",
    "                    wrdFile.write(str(stdDev) + \", \")\n",
    "\n",
    "                    # normalize entries between -1 and 1\n",
    "                    normSensorVals = normalize(sensorVals)\n",
    "\n",
    "                    # quantizes entries into 2r levels as in phase 1\n",
    "                    quantizedSensor = quantize(normSensorVals, bands)\n",
    "\n",
    "                    # moves a w-length window on time series (by shifting it s units at a time), and at position h\n",
    "                    sensorWords = getWords()\n",
    "\n",
    "                    # computes and outputs in file average quantized amplitude avgQijh for window h of sensor sj\n",
    "                    avgQuanAmp = calcAvgQuanAmp()\n",
    "                    wrdFile.write(str(avgQuanAmp) + \", \" + \" - \")\n",
    "\n",
    "                    # computes and outputs symbolic quantized window descriptor winQijh for the window h of sensor sj\n",
    "                    wrdFile.write(str(sensorWords) + \"\\n\")\n",
    "\n",
    "                    # add dictionary of each window to gestureDict list\n",
    "                    for window in sensorWords:\n",
    "                        wordDict = (direct, sensor_id, window)\n",
    "                        gesture_dict.append(wordDict)\n",
    "                        addToUniqueDict(wordDict)\n",
    "\n",
    "                    sensor_id += 1\n",
    "        # The dictionary of the words consists of <componentName, sensorID, winQ>\n",
    "\n",
    "    # TASK 0B\n",
    "    for direct in os.listdir(directory):\n",
    "        # for each gesture file in W,X,Y,Z:\n",
    "        # create vector .txt files with tf and tf-idf values\n",
    "        for filename in os.listdir(directory + direct):\n",
    "            if filename.endswith(\".wrd\"):\n",
    "                tfFile = open(directory + direct + \"/tf_vectors_\" + filename[:-8] + \".txt\", \"w\")\n",
    "                tfidfFile = open(directory + direct + \"/tfidf_vectors_\" + filename[:-8] + \".txt\", \"w\")\n",
    "                gestureFile = directory + direct + \"/\" + filename\n",
    "\n",
    "                allWordsInGesture = getWordsFromFile(gestureFile)\n",
    "                uniqueWordsInGesture = getUniqueWordsInGesture(allWordsInGesture)\n",
    "\n",
    "                for word_tuple in uniqueWordsInGesture:\n",
    "                    tfValue = calcTfValue(word_tuple, allWordsInGesture)\n",
    "                    idfValue = calcIdfValue(word_tuple, direct)\n",
    "                    tf_idf_value = tfValue * idfValue\n",
    "                    tfFile.write(str(word_tuple) + \" - \" + str(tfValue) + \"\\n\")\n",
    "                    tfidfFile.write(str(word_tuple) + \" - \" + str(tf_idf_value) + \"\\n\")\n",
    "    # End of TASK1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the folder that you want analyzed: X\n",
      "Enter the vector model: tf\n",
      "Enter k: 10\n",
      "Enter the analysis you would like to use: PCA\n",
      "\n",
      "PCA for X gesture files:\n",
      "\n",
      "           0         1         2         3             4         5         6  \\\n",
      "0  -0.000480  0.000227 -0.001063 -0.000787 -1.005553e-03 -0.000669 -0.000198   \n",
      "1  -0.000369  0.002683  0.001072  0.001510  3.676731e-04  0.000201 -0.000367   \n",
      "2  -0.000843  0.001064 -0.000702  0.001453  1.707200e-03  0.000370 -0.000599   \n",
      "3  -0.000873 -0.004965  0.001652 -0.000972  5.301453e-05  0.000501 -0.000417   \n",
      "4  -0.000880  0.004374  0.001140 -0.000489  6.634885e-04  0.000546  0.000378   \n",
      "5   0.002475  0.004596 -0.002581  0.001581 -1.392592e-03  0.001268 -0.000260   \n",
      "6  -0.000052 -0.000070 -0.004286 -0.000525  2.149026e-03  0.001190  0.000853   \n",
      "7  -0.000590  0.001440  0.002026  0.000381  2.753112e-04  0.000539 -0.000114   \n",
      "8   0.001047 -0.002799 -0.003183  0.001032  9.275303e-07  0.001444  0.000190   \n",
      "9   0.000715 -0.000392  0.004236  0.001383 -2.554074e-03  0.000545 -0.000428   \n",
      "10 -0.003706 -0.002263  0.002942 -0.002709 -5.867603e-04 -0.000210 -0.000034   \n",
      "11 -0.000077 -0.002495  0.001118  0.001076 -1.196164e-03  0.000127  0.000177   \n",
      "12  0.002368 -0.000184 -0.002559 -0.001202  7.374295e-04 -0.000161  0.000339   \n",
      "13  0.000865  0.001270  0.002577  0.000928  5.479907e-05  0.000399 -0.000196   \n",
      "14  0.000547  0.002017 -0.002777 -0.001533 -1.475694e-03  0.000243 -0.000400   \n",
      "15  0.001355  0.002844 -0.004344 -0.001383 -2.006442e-03 -0.000617 -0.000734   \n",
      "16  0.000397 -0.001567 -0.002022  0.000045 -1.212081e-03 -0.001535 -0.000296   \n",
      "17  0.000957  0.001453 -0.002981  0.000854 -3.995848e-04 -0.000790 -0.000151   \n",
      "18  0.000004 -0.001419 -0.002595  0.000278  2.078852e-05 -0.001036 -0.000839   \n",
      "19  0.002038 -0.002807 -0.001276  0.001694 -2.152929e-03 -0.000377  0.002191   \n",
      "20  0.000879 -0.001187 -0.001697  0.001136 -1.897838e-03 -0.000885 -0.000019   \n",
      "21  0.001273  0.000338 -0.001664  0.004647  2.890630e-03 -0.001473 -0.000440   \n",
      "22 -0.001018  0.001401  0.001387 -0.000139 -4.849234e-04 -0.000060 -0.000096   \n",
      "23  0.000017 -0.000869 -0.001326  0.000344  4.666638e-04 -0.000141 -0.000694   \n",
      "24 -0.000558  0.002772 -0.001344 -0.000300  1.838063e-04 -0.000877  0.000790   \n",
      "25  0.030826 -0.000954  0.002621 -0.002080  1.065033e-03 -0.000166 -0.000010   \n",
      "26 -0.000704  0.001120  0.000076 -0.000260 -3.759361e-04 -0.000407 -0.000801   \n",
      "27  0.001437  0.004504  0.001662  0.001556 -2.453292e-03  0.000099  0.000419   \n",
      "28 -0.003209  0.002461  0.004783 -0.001573  1.218083e-03  0.000100  0.000536   \n",
      "29 -0.001640  0.000469  0.000203 -0.001119 -8.281427e-05 -0.000233  0.000274   \n",
      "30 -0.001400 -0.000002  0.002171  0.000868 -2.306070e-04 -0.000486 -0.000059   \n",
      "31  0.000362  0.001545  0.000344  0.001919 -7.150247e-04 -0.000061 -0.000127   \n",
      "32 -0.002791 -0.004120  0.001717 -0.002087 -1.216169e-03 -0.000018  0.000382   \n",
      "33 -0.002108 -0.002958  0.002513  0.000004  9.218263e-04 -0.000441 -0.000090   \n",
      "34  0.000406 -0.000156  0.002167  0.002508  2.395344e-04  0.000755  0.000474   \n",
      "35 -0.000296  0.007040  0.000328  0.000098  4.208401e-04  0.000397  0.000018   \n",
      "36 -0.001421 -0.002884 -0.000624 -0.000778  2.672274e-04 -0.000283 -0.000322   \n",
      "37 -0.001488  0.009517 -0.000936 -0.001553  3.060432e-04  0.000369 -0.000050   \n",
      "38 -0.003169 -0.000071  0.002537 -0.001725  1.148720e-03  0.000198 -0.000375   \n",
      "39 -0.000092 -0.004139 -0.003701 -0.001213 -7.874023e-04  0.002001 -0.000840   \n",
      "40 -0.001305 -0.003136 -0.001182  0.000746  1.935352e-03  0.000983  0.001381   \n",
      "41 -0.000756 -0.000230  0.002460  0.002160  4.247958e-04  0.000563 -0.000454   \n",
      "42 -0.000422 -0.003428 -0.003397 -0.001261 -5.492653e-04  0.000256  0.000930   \n",
      "43 -0.000080 -0.000666  0.000564  0.001009 -1.436101e-03 -0.000636  0.000487   \n",
      "44 -0.002014 -0.001251  0.003342 -0.001400  1.395072e-03 -0.000363  0.000509   \n",
      "45 -0.000853 -0.001164 -0.003226  0.000262  2.522720e-03 -0.000049 -0.001118   \n",
      "46 -0.001278 -0.001117 -0.002281  0.000201  2.028447e-03 -0.000804  0.000342   \n",
      "47 -0.001013  0.000704  0.001706  0.000675 -8.070392e-04 -0.000603 -0.000262   \n",
      "48 -0.000733  0.000516 -0.002378 -0.001163 -5.336056e-04 -0.000079  0.000701   \n",
      "49 -0.003404 -0.000666  0.000246 -0.002665  1.151172e-03 -0.001277  0.000320   \n",
      "50 -0.000436 -0.000585 -0.000790  0.001648  1.226976e-03 -0.000057  0.000775   \n",
      "51 -0.002373 -0.002366  0.002082 -0.001360  8.968538e-05 -0.000112 -0.000737   \n",
      "52 -0.000807 -0.002243 -0.000939 -0.000160 -5.098123e-04  0.000935 -0.000124   \n",
      "53 -0.001663 -0.003467  0.000066 -0.000903 -1.743748e-04  0.000011 -0.000521   \n",
      "54 -0.000902  0.000615 -0.000461 -0.001250 -3.728173e-04  0.000733 -0.000591   \n",
      "55  0.000094 -0.004090  0.003570  0.002381  3.354121e-04  0.000319 -0.000509   \n",
      "56 -0.000756 -0.001334  0.000587  0.000223 -5.711509e-04 -0.000095  0.000163   \n",
      "57 -0.001111  0.006537  0.000840 -0.001864  9.270329e-04  0.000045  0.000181   \n",
      "58  0.001008 -0.001298 -0.000010  0.000064 -1.193674e-04  0.000066 -0.000347   \n",
      "59 -0.001400  0.001834  0.001588 -0.000210  1.046853e-04 -0.000204  0.000815   \n",
      "\n",
      "           7         8         9  \n",
      "0  -0.000565  0.000114 -0.000642  \n",
      "1  -0.000277 -0.000449  0.000051  \n",
      "2   0.000276 -0.000434  0.000090  \n",
      "3  -0.000443  0.000914 -0.000441  \n",
      "4   0.000341  0.000235 -0.000221  \n",
      "5  -0.000167 -0.000714  0.000331  \n",
      "6  -0.001103  0.001946  0.000354  \n",
      "7   0.000147  0.000154  0.000209  \n",
      "8   0.000924 -0.000398 -0.001157  \n",
      "9   0.000186  0.000831 -0.000035  \n",
      "10  0.000119  0.000046  0.000754  \n",
      "11 -0.000306 -0.000041 -0.000790  \n",
      "12  0.001095  0.000021  0.000152  \n",
      "13 -0.000277 -0.000126 -0.000071  \n",
      "14  0.001348  0.000027  0.000534  \n",
      "15  0.000206  0.000121 -0.000814  \n",
      "16 -0.000849  0.000535  0.001024  \n",
      "17 -0.000983 -0.000464 -0.000897  \n",
      "18 -0.000104  0.000015 -0.000125  \n",
      "19  0.000362  0.000448 -0.000246  \n",
      "20 -0.000272  0.000197  0.000963  \n",
      "21  0.000133 -0.000319  0.000220  \n",
      "22  0.000066  0.000113  0.000138  \n",
      "23  0.000652  0.001374  0.000291  \n",
      "24 -0.001095  0.000240 -0.000889  \n",
      "25 -0.000102 -0.000124  0.000005  \n",
      "26  0.000121 -0.000225 -0.000191  \n",
      "27 -0.000304  0.000419  0.000163  \n",
      "28 -0.000017 -0.000153  0.000350  \n",
      "29  0.000397 -0.001085 -0.000466  \n",
      "30 -0.000340 -0.000528 -0.000116  \n",
      "31  0.000280 -0.000101 -0.000024  \n",
      "32  0.000161 -0.000534 -0.000062  \n",
      "33  0.000568  0.000395 -0.000188  \n",
      "34 -0.000066 -0.000302  0.000626  \n",
      "35  0.000358 -0.000088  0.000116  \n",
      "36 -0.000055 -0.000716  0.000147  \n",
      "37  0.000206  0.000210  0.000202  \n",
      "38 -0.000046  0.000081 -0.000277  \n",
      "39 -0.000915 -0.000962  0.001303  \n",
      "40 -0.000332 -0.000126 -0.000633  \n",
      "41 -0.000453  0.000233  0.000176  \n",
      "42  0.000974 -0.000403  0.000231  \n",
      "43  0.001017  0.000338  0.000371  \n",
      "44 -0.000506 -0.000316  0.000561  \n",
      "45  0.000588  0.000686 -0.000354  \n",
      "46 -0.000491 -0.000754  0.000809  \n",
      "47 -0.000103 -0.000085 -0.000185  \n",
      "48 -0.000511 -0.000798  0.000110  \n",
      "49  0.000613  0.000118  0.000100  \n",
      "50  0.000546 -0.000190  0.000175  \n",
      "51 -0.000374 -0.000547 -0.000957  \n",
      "52 -0.000077  0.000051 -0.000309  \n",
      "53  0.000026  0.000614  0.000019  \n",
      "54 -0.000650  0.000334 -0.000424  \n",
      "55  0.000747 -0.000092 -0.000118  \n",
      "56 -0.000264  0.000131  0.000430  \n",
      "57  0.000267  0.000082 -0.000031  \n",
      "58 -0.000134 -0.000008 -0.000128  \n",
      "59 -0.000544  0.000060 -0.000214  \n"
     ]
    }
   ],
   "source": [
    "#Task 1\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#returns the top-k topics \n",
    "def PCAsetup(wordMat, k):\n",
    "    #calculate PCA\n",
    "    pca = PCA(k)\n",
    "    pc = pca.fit_transform(wordMat)\n",
    "    topK = pd.DataFrame(data = pc)\n",
    "    \n",
    "    return topK\n",
    "\n",
    "def SVD(k):\n",
    "    return topK\n",
    "\n",
    "def NMF(k):\n",
    "    return topK\n",
    "\n",
    "def LDA(k):\n",
    "    return topK\n",
    "\n",
    "\n",
    "def makeMat(vectModel, axis):\n",
    "        \n",
    "    #read files\n",
    "    if vectModel == \"tf\":\n",
    "        Xmat = []\n",
    "        for file in glob.glob(directory + axis + \"/tf_vectors_*.txt\"):\n",
    "            #read tf file\n",
    "            f = open(file, \"r\")\n",
    "            tf_vectors = f.readlines()\n",
    "        \n",
    "            gestWords = []\n",
    "            tfVals = []\n",
    "        \n",
    "            #split the line into the word and tf value\n",
    "            for line in tf_vectors:\n",
    "                noDash = line.split(\"-\")\n",
    "                tf_val = noDash[1]\n",
    "                word = noDash[0].split(\",\")\n",
    "                word[2] = word[2].replace(\")\",\"\")\n",
    "                word[2] = word[2].replace(\"'\", \"\")\n",
    "                word[2] = word[2].replace(\" \", \"\")\n",
    "                tf_val = tf_val.replace(\"\\n\", \"\")\n",
    "                gestWords.append(word[2])\n",
    "                tfVals.append(tf_val)\n",
    "           \n",
    "        \n",
    "            index = 0\n",
    "            startI = \"1\"\n",
    "            for y in range(1, w):\n",
    "                startI = startI + \"1\"\n",
    "            startI = int(startI)\n",
    "        \n",
    "            #create dictionary with every word\n",
    "            numWords = startI * (2*r) - startI\n",
    "            wordMat = []\n",
    "    \n",
    "            for i in range(0, numWords + 1):\n",
    "                wordMat.append(0)\n",
    "            \n",
    "            # put tf values into matrix where column = word\n",
    "            for x in gestWords:\n",
    "                xint = int(x)\n",
    "            \n",
    "                #if wordMat[xint - startI] == 0:\n",
    "                wordMat[xint - startI] = wordMat[xint - startI] + float(tfVals[index])\n",
    "                index = index + 1\n",
    "                \n",
    "            \n",
    "            for iterate in range(0, len(wordMat)):\n",
    "                wordMat[iterate] = wordMat[iterate] / 20\n",
    "\n",
    "            Xmat.append(wordMat)\n",
    "            f.close()\n",
    "           \n",
    "        return Xmat\n",
    "    \n",
    "    elif vectModel == \"idf\":\n",
    "        return wordMat\n",
    "    \n",
    "def task1(gestfiles, vectModel, useOp, k):\n",
    "    \n",
    "    if useOp == \"PCA\":\n",
    "        #PCA for X axis\n",
    "        wordMat = makeMat(vectModel, gestfiles)\n",
    "        topk = PCAsetup(wordMat, k)\n",
    "        print(\"\\nPCA for \" + gestfiles + \" gesture files:\\n\")\n",
    "        print(topk)\n",
    "        \n",
    "    elif useOp == \"SVD\":\n",
    "        topk = SVD(k)\n",
    "    elif useOp == \"NMF\":\n",
    "        topk = NMF(k)\n",
    "    elif useOp == \"LDA\":\n",
    "        topk = LDA(k)\n",
    "\n",
    "\n",
    "gestfiles = input(\"Enter the folder that you want analyzed: \")\n",
    "vectModel = input(\"Enter the vector model: \")\n",
    "k = input(\"Enter k: \")\n",
    "useOp = input(\"Enter the analysis you would like to use: \")\n",
    "k = int(k)\n",
    "task1(gestfiles, vectModel, useOp, k)\n",
    "\n",
    "#sample output: \n",
    "#Enter the folder that you want analyzed: X\n",
    "#Enter the vector model: tf\n",
    "#Enter k: 10\n",
    "#Enter the analysis you would like to use: PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
