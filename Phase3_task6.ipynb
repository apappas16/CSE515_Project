{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the following inputs as the same values you used for task 0: \n",
      "Enter the window length (ex: 3): 3\n",
      "Enter the shift length (ex: 3): 3\n",
      "Enter the resolution (ex: 3): 3\n",
      "Enter gesture file(e.g Data/1.csv) :\n",
      "* WARNING : Please make .pkl in TASK 1 before you use principal component\n",
      "Data/5.csv\n",
      "Enter vector model (tf, tfidf):\n",
      "tf\n",
      "Enter user options (1 ~ 7)\n",
      "* HINT : 1 = Dot similarity, 2 = PCA, 3 = SVD, 4 = NMF, 5 = LDA, 6 = Edit Distance, 7 = DTW\n",
      "2\n",
      "Most similar (gesture, score) \n",
      "(5, 1.0)\n",
      "(0, 0.9977428473237746)\n",
      "(55, 0.9977250998068912)\n",
      "(11, 0.972983123489022)\n",
      "(8, 0.8210591907732581)\n",
      "(12, 0.8042194956121744)\n",
      "(25, 0.799804646178491)\n",
      "(43, 0.7614281955338085)\n",
      "(3, 0.6957418909314206)\n",
      "(30, 0.6044968401955814)\n",
      "Please enter the relevence technique you would like (enter probabilistic or classifier_based): classifier_based\n",
      "Please enter the number of results you would like to recieve: (ex: 5): 5\n",
      "Would you like to provide feedback to improve your query output? (enter Y/N): Y\n",
      "Enter the irrelevent results in a list (ex: 11 3 4): 0 8 43\n",
      "Enter the relevent results in a list (ex: 26 52): 30 3 12\n",
      "Would you like to provide feedback to improve your query output? (enter Y/N): N\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#Phase2 Task 2 code\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity                          \n",
    "from math import log\n",
    "import re\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log2\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "print(\"Please enter the following inputs as the same values you used for task 0: \")\n",
    "#directory = input(\"Enter the data directory path (ex: Data/: \")\n",
    "w = input(\"Enter the window length (ex: 3): \")\n",
    "s = input(\"Enter the shift length (ex: 3): \")\n",
    "r = input(\"Enter the resolution (ex: 3): \")\n",
    "\n",
    "w = int(w)\n",
    "s = int(s)\n",
    "r = int(r)\n",
    "\n",
    "def makeMat(vectModel):    \n",
    "    #read files\n",
    "    Wmat = []\n",
    "    Xmat = []\n",
    "    Ymat = []\n",
    "    Zmat = []\n",
    "    if vectModel == \"tf\":\n",
    "        for axisNum in range(1, 5):\n",
    "            if axisNum == 1:\n",
    "                axis = 'W'\n",
    "            elif axisNum == 2:\n",
    "                axis = 'X'\n",
    "            elif axisNum == 3:\n",
    "                axis = 'Y'\n",
    "            elif axisNum == 4:\n",
    "                axis = 'Z'\n",
    "                \n",
    "            for file in glob.glob(directory + axis + \"/tf_vectors_*.txt\"):\n",
    "                #Xmat = []\n",
    "                #read tf file\n",
    "                f = open(file, \"r\")\n",
    "                tf_vectors = f.readlines()\n",
    "        \n",
    "                gestWords = []\n",
    "                tfVals = []\n",
    "        \n",
    "                #split the line into the word and tf value\n",
    "                for line in tf_vectors:\n",
    "                    noDash = line.split(\"-\")\n",
    "                    tf_val = noDash[1]\n",
    "                    tf_val = tf_val.replace(\"\\n\", \"\")\n",
    "                    gestWords.append(noDash[0])\n",
    "                    tfVals.append(tf_val)\n",
    "           \n",
    "        \n",
    "                index = 0\n",
    "                startI = \"1\"\n",
    "                for y in range(1, w):\n",
    "                    startI = startI + \"1\"\n",
    "                startI = int(startI)\n",
    "        \n",
    "                #create dictionary with every word for every sensor and every directory\n",
    "                numWords = (startI * (2*r) - startI) * 20\n",
    "                wordMat = []\n",
    "    \n",
    "                for i in range(0, numWords + 20):\n",
    "                    wordMat.append(0)\n",
    "                \n",
    "                # put tf values into matrix where column = word\n",
    "                for x in gestWords:\n",
    "                    word = x.split(\", \")\n",
    "                    sensorNum = word[1].replace(\"'\", \"\")\n",
    "                    wordID = word[2].replace(\"'\", \"\")\n",
    "                    wordID = wordID.replace(\")\", \"\")\n",
    "                \n",
    "                    wordID = int(wordID)\n",
    "                    sensorNum = int(sensorNum)\n",
    "                \n",
    "                    #axisSplit = len(wordMat) / 4\n",
    "                    sensorSplit = len(wordMat) / 20\n",
    "                    \n",
    "                    wordIndex = int(wordID + ((sensorNum - 1) * sensorSplit)) #+ ((axisNum - 1) * axisSplit)))\n",
    "                    wordIndex = wordIndex - startI\n",
    "            \n",
    "                    wordMat[wordIndex] = float(tfVals[index])\n",
    "                    index = index + 1\n",
    "                \n",
    "\n",
    "                if axisNum == 1:\n",
    "                    axis = 'W'\n",
    "                    Wmat.append(wordMat)\n",
    "                elif axisNum == 2:\n",
    "                    axis = 'X'\n",
    "                    Xmat.append(wordMat)\n",
    "                elif axisNum == 3:\n",
    "                    axis = 'Y'\n",
    "                    Ymat.append(wordMat)\n",
    "                elif axisNum == 4:\n",
    "                    axis = 'Z'\n",
    "                    Zmat.append(wordMat)\n",
    "                f.close()\n",
    "                \n",
    "        finalMat = np.append(Wmat, Xmat, axis = 1)\n",
    "        finalMat = np.append(finalMat, Ymat, axis = 1)\n",
    "        finalMat = np.append(finalMat, Zmat, axis = 1)\n",
    "        \n",
    "        #print(finalMat)\n",
    "        \n",
    "        return finalMat\n",
    "            #print(Xmat)\n",
    "    \n",
    "    elif vectModel == \"tfidf\":\n",
    "        for axisNum in range(1, 5):\n",
    "            if axisNum == 1:\n",
    "                axis = 'W'\n",
    "            elif axisNum == 2:\n",
    "                axis = 'X'\n",
    "            elif axisNum == 3:\n",
    "                axis = 'Y'\n",
    "            elif axisNum == 4:\n",
    "                axis = 'Z'\n",
    "                \n",
    "            for file in glob.glob(directory + axis + \"/tfidf_vectors_*.txt\"):\n",
    "                #read tf file\n",
    "                f = open(file, \"r\")\n",
    "                tf_vectors = f.readlines()\n",
    "        \n",
    "                gestWords = []\n",
    "                tfVals = []\n",
    "        \n",
    "                #split the line into the word and tf value\n",
    "                for line in tf_vectors:\n",
    "                    noDash = line.split(\"-\")\n",
    "                    tf_val = noDash[1]\n",
    "                    tf_val = tf_val.replace(\"\\n\", \"\")\n",
    "                    gestWords.append(noDash[0])\n",
    "                    tfVals.append(tf_val)\n",
    "           \n",
    "        \n",
    "                index = 0\n",
    "                startI = \"1\"\n",
    "                for y in range(1, w):\n",
    "                    startI = startI + \"1\"\n",
    "                startI = int(startI)\n",
    "        \n",
    "                #create dictionary with every word for every sensor and every directory\n",
    "                numWords = (startI * (2*r) - startI) * 20\n",
    "                wordMat = []\n",
    "    \n",
    "                for i in range(0, numWords + 20):\n",
    "                    wordMat.append(0)\n",
    "                \n",
    "                # put tf values into matrix where column = word\n",
    "                for x in gestWords:\n",
    "                    word = x.split(\", \")\n",
    "                    sensorNum = word[1].replace(\"'\", \"\")\n",
    "                    wordID = word[2].replace(\"'\", \"\")\n",
    "                    wordID = wordID.replace(\")\", \"\")\n",
    "                \n",
    "                    wordID = int(wordID)\n",
    "                    sensorNum = int(sensorNum)\n",
    "                \n",
    "                    #axisSplit = len(wordMat) / 4\n",
    "                    sensorSplit = len(wordMat) / 20\n",
    "                    \n",
    "                    wordIndex = int(wordID + ((sensorNum - 1) * sensorSplit)) #+ ((axisNum - 1) * axisSplit)))\n",
    "                    wordIndex = wordIndex - startI\n",
    "            \n",
    "                    wordMat[wordIndex] = float(tfVals[index])\n",
    "                    index = index + 1\n",
    "                \n",
    "\n",
    "                if axisNum == 1:\n",
    "                    axis = 'W'\n",
    "                    Wmat.append(wordMat)\n",
    "                elif axisNum == 2:\n",
    "                    axis = 'X'\n",
    "                    Xmat.append(wordMat)\n",
    "                elif axisNum == 3:\n",
    "                    axis = 'Y'\n",
    "                    Ymat.append(wordMat)\n",
    "                elif axisNum == 4:\n",
    "                    axis = 'Z'\n",
    "                    Zmat.append(wordMat)\n",
    "                f.close()\n",
    "           \n",
    "        finalMat = np.append(Wmat, Xmat, axis = 1)\n",
    "        finalMat = np.append(finalMat, Ymat, axis = 1)\n",
    "        finalMat = np.append(finalMat, Zmat, axis = 1)\n",
    "        \n",
    "        #print(finalMat)\n",
    "        \n",
    "        return finalMat\n",
    "            #print(Xmat)\n",
    "\n",
    "def dot_similarity(gesture1, gesture2):                  \n",
    "    x = np.array(gesture1)\n",
    "    y = np.array(gesture2)\n",
    "    \"\"\"if len(x) > len(y):\n",
    "        y = np.pad(y, (0, len(x) - len(y)))\n",
    "    else:\n",
    "        x = np.pad(x, (0, len(y) - len(x)))\"\"\"\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def pears_similarity(vec1, vec2):\n",
    "    pearson_coef, p_value = stats.pearsonr(vec1, vec2)\n",
    "    return pearson_coef\n",
    "    \n",
    "def cos_similarity(vec1, vec2):                            \n",
    "    x = np.array(vec1)\n",
    "    y = np.array(vec2)                                                    \n",
    "    similarity = 1- spatial.distance.cosine(x, y)                             \n",
    "                                                                            \n",
    "    return similarity                             \n",
    "\n",
    "def KL_div_similarity(p, q):\n",
    "    return sum(p[i] * log2(p[i]/q[i]) for i in range(len(p)))\n",
    "\n",
    "def edit_distance(sensor1, sensor2, m, n):\n",
    "    # Create a table to store results of subproblems \n",
    "    dp = [[0 for x in range(n + 1)] for x in range(m + 1)] \n",
    "  \n",
    "    # Fill d[][] in bottom up manner \n",
    "    for i in range(m + 1): \n",
    "        for j in range(n + 1): \n",
    "  \n",
    "            # If first string is empty, only option is to \n",
    "            # insert all characters of second string \n",
    "            if i == 0: \n",
    "                dp[i][j] = j    # Min. operations = j \n",
    "  \n",
    "            # If second string is empty, only option is to \n",
    "            # remove all characters of second string \n",
    "            elif j == 0: \n",
    "                dp[i][j] = i    # Min. operations = i \n",
    "  \n",
    "            # If last characters are same, ignore last char \n",
    "            # and recur for remaining string \n",
    "            elif sensor1[i-1] == sensor2[j-1]: \n",
    "                dp[i][j] = dp[i-1][j-1] \n",
    "  \n",
    "            # If last character are different, consider all \n",
    "            # possibilities and find minimum \n",
    "            else: \n",
    "                dp[i][j] = 1 + min(dp[i][j-1],        # Insert \n",
    "                                   dp[i-1][j],        # Remove \n",
    "                                   dp[i-1][j-1])    # Replace \n",
    "  \n",
    "    return dp[m][n] \n",
    "    \n",
    "def dynamic_time_warping(sensor1, sensor2, m, n):\n",
    "    dp = [[0 for x in range(n+1)] for x in range(m+1)] \n",
    "    \n",
    "    for i in range(1, m+1): \n",
    "        for j in range(1, n+1): \n",
    "            dp[i][j] = abs(sensor1[i-1] - sensor2[j-1])\n",
    "             \n",
    "            if i == 1 and j == 1:\n",
    "                continue\n",
    "            elif i == 1 and j != 1:\n",
    "                dp[i][j] += dp[i][j-1] \n",
    "            elif i != 1 and j == 1:\n",
    "                dp[i][j] += dp[i-1][j]\n",
    "            else:\n",
    "                dp[i][j] += min(dp[i][j-1],        # Insert \n",
    "                                dp[i-1][j],        # Remove \n",
    "                                dp[i-1][j-1])    # Replace \n",
    "            \n",
    "    return dp[m][n] \n",
    "\n",
    "def tfidf_loader(directory):\n",
    "    gestures = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.startswith(\"tfidf_\") or not filename.endswith(\".txt\") :\n",
    "            continue\n",
    "            \n",
    "        path = directory+\"/\"+filename\n",
    "        with open(path, \"r\") as w:\n",
    "            gesture = w.readlines()\n",
    "\n",
    "        matrix=[]\n",
    "\n",
    "        for sensor in gesture :\n",
    "            tfidf = float(sensor.split(\"-\")[1].strip())\n",
    "            matrix.append(tfidf)\n",
    "                \n",
    "        gestures.append(matrix)\n",
    "        \n",
    "    return gestures\n",
    "    \n",
    "    \n",
    "def tf_loader(directory):\n",
    "    gestures = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.startswith(\"tf_\") or not filename.endswith(\".txt\") :\n",
    "            continue\n",
    "            \n",
    "        path = directory+\"/\"+filename\n",
    "        with open(path, \"r\") as w:\n",
    "            gesture = w.readlines()\n",
    "\n",
    "        matrix=[]\n",
    "\n",
    "        for sensor in gesture :\n",
    "            tf = float(sensor.split(\"-\")[1].strip())   \n",
    "            matrix.append(tf)\n",
    "        gestures.append(matrix)\n",
    "        \n",
    "    return gestures\n",
    "    \n",
    "def symbol_loader(directory):\n",
    "    gestures = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".wrd\") :\n",
    "            continue\n",
    "        path = directory+\"/\"+filename\n",
    "        with open(path, \"r\") as w:\n",
    "            gesture = w.readlines()\n",
    "\n",
    "        matrix=[]\n",
    "\n",
    "        for sensor in gesture :\n",
    "            sym_quant_window = [re.findall(r'\\d+',word)[0] for word in sensor.split(\" - \")[1].split(\",\")] \n",
    "            matrix.append(sym_quant_window)\n",
    "                \n",
    "        gestures.append(matrix)\n",
    "        \n",
    "    return gestures\n",
    "\n",
    "def amplitude_loader(directory):\n",
    "    gestures = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".wrd\") :\n",
    "            continue\n",
    "        path = directory+\"/\"+filename\n",
    "        with open(path, \"r\") as w:\n",
    "            gesture = w.readlines()\n",
    "\n",
    "        matrix=[]\n",
    "\n",
    "        for sensor in gesture :\n",
    "            avg_quant_ampitude = [float(word) for word in sensor.split(\" - \")[0].split(\"[\")[1].replace(\"],\",\"\").split(\",\")]\n",
    "            matrix.append(avg_quant_ampitude)\n",
    "                \n",
    "        gestures.append(matrix)\n",
    "        \n",
    "    return gestures\n",
    "\n",
    "###### GET Input from users######\n",
    "print(\"Enter gesture file(e.g Data/1.csv) :\")\n",
    "print(\"* WARNING : Please make .pkl in TASK 1 before you use principal component\")\n",
    "gesture_path = input()\n",
    "\n",
    "directory = gesture_path.split(\"/\")[0]\n",
    "#axis = gesture_path.split(\"/\")[1]\n",
    "filename = gesture_path.split(\"/\")[1]\n",
    "key_idx = int(re.findall(r'\\d+', filename)[0])\n",
    "\n",
    "print(\"Enter vector model (tf, tfidf):\")\n",
    "vector_model = input()\n",
    "\n",
    "print(\"Enter user options (1 ~ 7)\")\n",
    "print(\"* HINT : 1 = Dot similarity, 2 = PCA, 3 = SVD, 4 = NMF, 5 = LDA, 6 = Edit Distance, 7 = DTW\")\n",
    "user_option = int(input())  \n",
    "\n",
    "#Retrieve only top 10 gestures with high similarity\n",
    "top_K = 10\n",
    "\n",
    "#Calculate similarity(cost) based on User options\n",
    "if user_option == 1 :\n",
    "    directory = directory + \"/\"\n",
    "    gestures = makeMat(vector_model)\n",
    "    directory = directory.replace(\"/\", \"\")\n",
    "    \n",
    "    cost=[]\n",
    "    key_gesture = gestures[key_idx]\n",
    "    for gesture in gestures :\n",
    "        similarity = dot_similarity(key_gesture, gesture)\n",
    "        cost.append(similarity)\n",
    "    cost_top_K = sorted(cost, reverse=True)[0:top_K]                                        \n",
    "    \n",
    "elif user_option == 2 :\n",
    "    PC_path = [\"PCA\", vector_model]\n",
    "    PC_path = \"_\".join(PC_path)\n",
    "    pca = pd.read_pickle(PC_path + \".pkl\")\n",
    "    num = len(pca[0])\n",
    "\n",
    "    pca = pca.T\n",
    "    key_vec = pca[key_idx]\n",
    "    cost=[]\n",
    "    for idx in range(num) :\n",
    "        similarity = pears_similarity(key_vec, pca[idx])\n",
    "        cost.append(similarity)\n",
    "    cost_top_K = sorted(cost, reverse=True)[0:top_K]                                        \n",
    "\n",
    "elif user_option == 3 : \n",
    "    PC_path = [\"SVD\", vector_model]\n",
    "    PC_path = \"_\".join(PC_path)\n",
    "    svd = pd.read_pickle(PC_path + \".pkl\")                                      \n",
    "    num = len(svd[0])                                                           \n",
    "                                                                                \n",
    "    svd = svd.T                                                                 \n",
    "    key_vec = svd[key_idx]      \n",
    "    \n",
    "    cost=[]                                                                     \n",
    "    for idx in range(num) :                                                     \n",
    "        similarity = cos_similarity(key_vec, svd[idx])                            \n",
    "        cost.append(similarity)                 \n",
    "    cost_top_K = sorted(cost, reverse=True)[0:top_K]                                        \n",
    "    \n",
    "elif user_option == 4 :                                                         \n",
    "    PC_path = [\"NMF\", vector_model]\n",
    "    PC_path = \"_\".join(PC_path)\n",
    "    nmf = pd.read_pickle(PC_path + \".pkl\")\n",
    "    num = len(nmf[0])                                                           \n",
    "                                                                                \n",
    "    nmf = nmf.T                                                                 \n",
    "    key_vec = nmf[key_idx]    \n",
    "    \n",
    "    cost=[]                                                                     \n",
    "    for idx in range(num) :                                                     \n",
    "        similarity = cos_similarity(key_vec, nmf[idx])                            \n",
    "        cost.append(similarity)           \n",
    "    cost_top_K = sorted(cost, reverse=True)[0:top_K]                                        \n",
    "                  \n",
    "elif user_option == 5 :                                                         \n",
    "    PC_path = [\"LDA\", vector_model]\n",
    "    PC_path = \"_\".join(PC_path)\n",
    "    lda = pd.read_pickle(PC_path + \".pkl\")\n",
    "    num = len(lda[0])                                                           \n",
    "                                                                                \n",
    "    lda = lda.T                                                                 \n",
    "    key_vec = lda[key_idx]    \n",
    "    \n",
    "    cost=[]                                                                     \n",
    "    for idx in range(num) :                                                     \n",
    "        similarity = KL_div_similarity(key_vec, lda[idx])                            \n",
    "        cost.append(similarity)                                  \n",
    "    cost_top_K = sorted(cost, reverse=True)[0:top_K]                                        \n",
    "\n",
    "elif user_option == 6 :\n",
    "    pathW = directory + \"/W\"\n",
    "    pathX = directory + \"/X\"\n",
    "    pathY = directory + \"/Y\"\n",
    "    pathZ = directory + \"/Z\"\n",
    "    gesturesW = symbol_loader(pathW)\n",
    "    gesturesX = symbol_loader(pathX)\n",
    "    gesturesY = symbol_loader(pathY)\n",
    "    gesturesZ = symbol_loader(pathZ)\n",
    "    \n",
    "    gestures = np.append(gesturesW, gesturesX, axis = 1)\n",
    "    gestures = np.append(gestures, gesturesY, axis = 1)\n",
    "    gestures = np.append(gestures, gesturesZ, axis = 1)\n",
    "        \n",
    "    key_gesture = gestures[key_idx]\n",
    "    \n",
    "    cost=[0]*len(gestures)\n",
    "    for i, gesture in enumerate(gestures) :\n",
    "        for j, sensor in enumerate(gesture) :\n",
    "            n = len(sensor)\n",
    "            m = len(key_gesture[j])\n",
    "            cost[i] += edit_distance(key_gesture[j], sensor, m, n)\n",
    "    cost_top_K = sorted(cost)[0:top_K]                                        \n",
    "\n",
    "elif user_option == 7 :\n",
    "    pathW = directory + \"/W\"\n",
    "    pathX = directory + \"/X\"\n",
    "    pathY = directory + \"/Y\"\n",
    "    pathZ = directory + \"/Z\"\n",
    "    gesturesW = amplitude_loader(pathW)\n",
    "    gesturesX = amplitude_loader(pathX)\n",
    "    gesturesY = amplitude_loader(pathY)\n",
    "    gesturesZ = amplitude_loader(pathZ)\n",
    "    \n",
    "    gestures = np.append(gesturesW, gesturesX, axis = 1)\n",
    "    gestures = np.append(gestures, gesturesY, axis = 1)\n",
    "    gestures = np.append(gestures, gesturesZ, axis = 1)\n",
    "    \n",
    "    key_gesture = gestures[key_idx]\n",
    "    \n",
    "    cost=[0]*len(gestures)\n",
    "    for i, gesture in enumerate(gestures) :                                     \n",
    "        for j, sensor in enumerate(gesture) :                                   \n",
    "            n = len(sensor)                                                     \n",
    "            m = len(key_gesture[j])                                             \n",
    "            cost[i] += dynamic_time_warping(key_gesture[j], sensor, m, n)    \n",
    "    cost_top_K = sorted(cost)[0:top_K]                                        \n",
    "else:\n",
    "    print(\"ERROR : No such user option in this program\")\n",
    "    \n",
    "       \n",
    "file = open(\"similarGesturesTask6.txt\", \"w\")\n",
    "outputList = []\n",
    "\n",
    "print(\"Most similar (gesture, score) \")              \n",
    "for k in cost_top_K :                                                       \n",
    "    print((cost.index(k), k))  \n",
    "    outputList.append((cost.index(k), k))\n",
    "file.write(str(outputList))\n",
    "    \n",
    "file.close()\n",
    "\n",
    "#end of phase2 Task2 code\n",
    "\n",
    "# task 6\n",
    "# requests the irrelevent results and produces a new query output based on those results.\n",
    "# calls again for more feedback if requested\n",
    "def feedbackInterface(taskNum):\n",
    "    irrelevent = input(\"Enter the irrelevent results in a list (ex: 11 3 4): \")\n",
    "    relevent = input(\"Enter the relevent results in a list (ex: 26 52): \")\n",
    "    \n",
    "    #convert strings to lists\n",
    "    irrlist = list(irrelevent.split(\" \"))\n",
    "    irreleventFile = open(\"irrelevent.txt\", \"a\")\n",
    "    irreleventFile.write(str(irrlist))\n",
    "    irreleventFile.close()\n",
    "    rlist = list(relevent.split(\" \"))\n",
    "    releventFile = open(\"relevent.txt\", \"w\")\n",
    "    releventFile.write(str(rlist))\n",
    "    releventFile.close()\n",
    "    \n",
    "    if taskNum == \"probabilistic\":\n",
    "        #call feedback function for task 4\n",
    "        #parameters: list of irrelevent results, list of relevent results, original guesture file\n",
    "        \n",
    "        feedback = input(\"Would you like to provide feedback to improve your query output? (enter Y/N): \")\n",
    "        if feedback == \"Y\":\n",
    "            feedbackInterface(taskNum)\n",
    "        elif feedback == \"N\":\n",
    "            sys.exit()\n",
    "        \n",
    "    elif taskNum == \"classifier_based\":\n",
    "        #call feedback function for task 5\n",
    "        #parameters: list of irrelevent results, list of relevent results, original guesture file\n",
    "        \n",
    "        feedback = input(\"Would you like to provide feedback to improve your query output? (enter Y/N): \")\n",
    "        if feedback == \"Y\":\n",
    "            feedbackInterface(taskNum)\n",
    "        elif feedback == \"N\":\n",
    "            sys.exit()\n",
    "            \n",
    "# starting interface\n",
    "run = True\n",
    "releventFile = open(\"relevent.txt\", \"w\")\n",
    "releventFile.write(\"\")\n",
    "irreleventFile = open(\"irrelevent.txt\", \"w\")\n",
    "irreleventFile.write(\"\")\n",
    "releventFile.close()\n",
    "irreleventFile.close()\n",
    "\n",
    "while run == True:\n",
    "    \"\"\"gestfile = input(\"W (ex: 1.csv, or exit for termination): \")\n",
    "    \n",
    "    #exit loop\n",
    "    if gestfile == \"exit\":\n",
    "        run = False\n",
    "        break\"\"\"\n",
    "\n",
    "    taskNum = input(\"Please enter the relevence technique you would like (enter probabilistic or classifier_based): \")\n",
    "    resultNum = input(\"Please enter the number of results you would like to recieve: (ex: 5): \")\n",
    "    \n",
    "    #call task 4 or 5 here:\n",
    "    if taskNum == \"probabilistic\":\n",
    "        #call task 4\n",
    "        #parameters: guesture file to find comparisons, number of results\n",
    "        \n",
    "        feedback = input(\"Would you like to provide feedback to improve your query output? (enter Y/N): \")\n",
    "        if feedback == \"Y\":\n",
    "            feedbackInterface(taskNum)\n",
    "        \n",
    "    elif taskNum == \"classifier_based\":\n",
    "        #call task 5\n",
    "        #parameters: guesture file to find comparisons, number of results\n",
    "        \n",
    "        feedback = input(\"Would you like to provide feedback to improve your query output? (enter Y/N): \")\n",
    "        if feedback == \"Y\":\n",
    "            feedbackInterface(taskNum)\n",
    "  \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
