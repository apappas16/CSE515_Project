{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the data directory path: Data/\n",
      "Enter the window length: 3\n",
      "Enter the shift length: 3\n",
      "Enter the resolution: 3\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "from scipy.integrate import quad\n",
    "\n",
    "\n",
    "def calcAvgSensorValue(sensorValues):\n",
    "    avg = sum(sensorValues) / len(sensorValues)\n",
    "    avg = round(avg, 9)\n",
    "    return avg\n",
    "\n",
    "\n",
    "def calcStdDev(sensorValues, meanVal):\n",
    "    sd = []\n",
    "    for num in sensorValues:\n",
    "        result = num - meanVal\n",
    "        result = result * result\n",
    "        sd.append(result)\n",
    "    return calcAvgSensorValue(sd)\n",
    "\n",
    "\n",
    "def normalize(sensorValues):\n",
    "    normalized_sensor = []\n",
    "    for val in sensorValues:\n",
    "        val = float(val)\n",
    "        normalized = 2 * ((val - min(sensorValues)) / (max(sensorValues) - min(sensorValues))) - 1\n",
    "        normalized_sensor.append(normalized)\n",
    "    return normalized_sensor\n",
    "\n",
    "\n",
    "def integral(i):\n",
    "    return getGaussianVal(i, 0, 0.25)\n",
    "\n",
    "\n",
    "def getGaussianVal(i, avg, sd):\n",
    "    i = float(i - avg) / sd\n",
    "    gauss = math.exp(-i * i / 2.0) / math.sqrt(2.0 * math.pi) / sd\n",
    "    return gauss\n",
    "\n",
    "\n",
    "def determineBands():\n",
    "    numBands = r * 2\n",
    "    bandList = []\n",
    "    bandStart = -1\n",
    "    for i in range(1, numBands):\n",
    "        integral1, e = quad(integral, (i - r - 1) / r, (i - r) / r)\n",
    "        integral2, e = quad(integral, -1, 1)\n",
    "        length_i = 2 * (integral1 / integral2)\n",
    "        band = bandStart + length_i\n",
    "        bandList.append(band)\n",
    "        bandStart = band\n",
    "    bandList.append(1.0)\n",
    "    return bandList\n",
    "\n",
    "\n",
    "def quantize(values, bandList):\n",
    "    quantized = \"\"\n",
    "    for i in range(len(values)):\n",
    "        bound = -1\n",
    "        for band in bandList:\n",
    "            if band >= values[i] > bound:\n",
    "                quantized += str(bandList.index(band) + 1)\n",
    "                break\n",
    "            else:\n",
    "                bound = band\n",
    "    return quantized\n",
    "\n",
    "\n",
    "def getWords():\n",
    "    wordList = []\n",
    "    i = 0\n",
    "    while (i + w - 1) < len(quantizedSensor):\n",
    "        word = quantizedSensor[i:i + w]\n",
    "        wordList.append(word)\n",
    "        i += s\n",
    "    return wordList\n",
    "\n",
    "\n",
    "def addToUniqueDict(word_tuple):\n",
    "    inList = False\n",
    "    for word in unique_dict:\n",
    "        if word == word_tuple:\n",
    "            inList = True\n",
    "            break\n",
    "    if not inList:\n",
    "        unique_dict.append(word_tuple)\n",
    "\n",
    "\n",
    "def calcAvgQuanAmp():\n",
    "    avgQuanAmpList = []\n",
    "    normWord = []\n",
    "    i = 0\n",
    "    while (i + w - 1) < len(normSensorVals):\n",
    "        word = normSensorVals[i:i + w]\n",
    "        normWord.append(word)\n",
    "        i += s\n",
    "\n",
    "    for word in normWord:\n",
    "        avgAmp = sum(word) / len(word)\n",
    "        avgQuanAmpList.append(avgAmp)\n",
    "\n",
    "    return avgQuanAmpList\n",
    "\n",
    "\n",
    "def getWordsFromFile(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        words = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            row = line.split(\" - [\")  # list of all words as they occur in the file\n",
    "            if len(row) > 1:\n",
    "                words.append(row[1])\n",
    "        f.close()\n",
    "    return formatWordsFromFile(words)\n",
    "\n",
    "\n",
    "def formatWordsFromFile(tempList):\n",
    "    allWords = []\n",
    "    for sensorWords in tempList:\n",
    "        sensorWords = sensorWords.replace(\"]\", \"\")\n",
    "        sensorWords = sensorWords.replace(\"'\", \"\")\n",
    "        wrd = sensorWords.split(\", \")\n",
    "        allWords.append(wrd)\n",
    "    return allWords\n",
    "\n",
    "\n",
    "def getUniqueWordsInGesture(allWordsInGesture):\n",
    "    uniqueWords = []\n",
    "    for i in range(len(allWordsInGesture)):  # i is each sensor in the gesture\n",
    "        for word in allWordsInGesture[i]:\n",
    "            uniqueWord = (direct, i+1, word)\n",
    "            if uniqueWord not in uniqueWords:\n",
    "                uniqueWords.append(uniqueWord)\n",
    "    return uniqueWords\n",
    "\n",
    "\n",
    "def calcTfValue(wordTuple, allWordsInFile):\n",
    "    totalWords = len(allWordsInFile[0]) * 20\n",
    "    num_occurs = 0\n",
    "    for sensor in range(len(allWordsInFile)):\n",
    "        for wrd in allWordsInFile[sensor]:\n",
    "            if wrd == wordTuple[2] and (sensor+1) == wordTuple[1]:\n",
    "                num_occurs += 1\n",
    "    value = num_occurs / totalWords\n",
    "    return value\n",
    "\n",
    "\n",
    "def calcIdfValue(wordTuple, direct):\n",
    "    numObjs = 60\n",
    "    numObjsWithWord = 1\n",
    "    sensorId = wordTuple[1]\n",
    "\n",
    "    for file in os.listdir(directory + direct):\n",
    "        if file != gestureFile and file.endswith(\".wrd\"):\n",
    "            file = directory + direct + \"/\" + file\n",
    "            gestFileWords = getWordsFromFile(file)\n",
    "            if word_tuple[2] in gestFileWords[sensorId-1]:\n",
    "                numObjsWithWord += 1\n",
    "                break\n",
    "\n",
    "    value = math.log(numObjs / numObjsWithWord)\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # GLOBAL VARIABLES:\n",
    "    unique_dict = []  # stores list of all unique words found\n",
    "    gesture_dict = []  # stores list of all words found across all files\n",
    "\n",
    "    # TASK 0\n",
    "    # TASK 0A\n",
    "    directory = input(\"Enter the data directory path: \")\n",
    "    w = input(\"Enter the window length: \")\n",
    "    s = input(\"Enter the shift length: \")\n",
    "    r = input(\"Enter the resolution: \")\n",
    "\n",
    "    w = int(w)\n",
    "    s = int(s)\n",
    "    r = int(r)\n",
    "\n",
    "    # for each data file create a .wrd file containing the following:\n",
    "    for direct in os.listdir(directory):\n",
    "        # for each csv file in X,Y,W,Z:\n",
    "        for filename in os.listdir(directory + direct):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                bands = determineBands()\n",
    "\n",
    "                # generate .wrd file\n",
    "                wrdFile = open(str(directory) + str(direct) + \"/\" + str(filename) + \".wrd\", \"w\")\n",
    "\n",
    "                sensor_id = 1\n",
    "                csvFile = open(str(directory) + str(direct) + \"/\" + filename, \"r\")\n",
    "                reader = csv.reader(csvFile, delimiter=',')\n",
    "                # for each sensor sj in file\n",
    "                for sensor in reader:\n",
    "                    # output component ID, c in output file\n",
    "                    wrdFile.write(str(direct) + \", \")\n",
    "\n",
    "                    # write sensorID to wrd file\n",
    "                    wrdFile.write(str(sensor_id) + \", \")\n",
    "\n",
    "                    # compute and output average amplitude, avgij of the values\n",
    "                    sensorVals = list(sensor)\n",
    "                    sensorVals = [float(i) for i in sensorVals]\n",
    "                    sensorAvg = calcAvgSensorValue(sensorVals)\n",
    "                    wrdFile.write(str(sensorAvg) + \", \")\n",
    "\n",
    "                    # compute and output standard deviations stdij of the values\n",
    "                    stdDev = calcStdDev(sensorVals, sensorAvg)\n",
    "                    wrdFile.write(str(stdDev) + \", \")\n",
    "\n",
    "                    # normalize entries between -1 and 1\n",
    "                    normSensorVals = normalize(sensorVals)\n",
    "\n",
    "                    # quantizes entries into 2r levels as in phase 1\n",
    "                    quantizedSensor = quantize(normSensorVals, bands)\n",
    "\n",
    "                    # moves a w-length window on time series (by shifting it s units at a time), and at position h\n",
    "                    sensorWords = getWords()\n",
    "\n",
    "                    # computes and outputs in file average quantized amplitude avgQijh for window h of sensor sj\n",
    "                    avgQuanAmp = calcAvgQuanAmp()\n",
    "                    wrdFile.write(str(avgQuanAmp) + \", \" + \" - \")\n",
    "\n",
    "                    # computes and outputs symbolic quantized window descriptor winQijh for the window h of sensor sj\n",
    "                    wrdFile.write(str(sensorWords) + \"\\n\")\n",
    "\n",
    "                    # add dictionary of each window to gestureDict list\n",
    "                    for window in sensorWords:\n",
    "                        wordDict = (direct, sensor_id, window)\n",
    "                        gesture_dict.append(wordDict)\n",
    "                        addToUniqueDict(wordDict)\n",
    "\n",
    "                    sensor_id += 1\n",
    "        # The dictionary of the words consists of <componentName, sensorID, winQ>\n",
    "\n",
    "    # TASK 0B\n",
    "    for direct in os.listdir(directory):\n",
    "        # for each gesture file in W,X,Y,Z:\n",
    "        # create vector .txt files with tf and tf-idf values\n",
    "        for filename in os.listdir(directory + direct):\n",
    "            if filename.endswith(\".wrd\"):\n",
    "                tfFile = open(directory + direct + \"/tf_vectors_\" + filename[:-8] + \".txt\", \"w\")\n",
    "                tfidfFile = open(directory + direct + \"/tfidf_vectors_\" + filename[:-8] + \".txt\", \"w\")\n",
    "                gestureFile = directory + direct + \"/\" + filename\n",
    "\n",
    "                allWordsInGesture = getWordsFromFile(gestureFile)\n",
    "                uniqueWordsInGesture = getUniqueWordsInGesture(allWordsInGesture)\n",
    "\n",
    "                for word_tuple in uniqueWordsInGesture:\n",
    "                    tfValue = calcTfValue(word_tuple, allWordsInGesture)\n",
    "                    idfValue = calcIdfValue(word_tuple, direct)\n",
    "                    tf_idf_value = tfValue * idfValue\n",
    "                    tfFile.write(str(word_tuple) + \" - \" + str(tfValue) + \"\\n\")\n",
    "                    tfidfFile.write(str(word_tuple) + \" - \" + str(tf_idf_value) + \"\\n\")\n",
    "    # End of TASK1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'w' from 'main' (C:\\Users\\alexs\\Documents\\Grad_hw\\CSE515\\CSE515_Project\\main.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0f6b239b542f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#unnecessary lines if you are using anaconda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'w' from 'main' (C:\\Users\\alexs\\Documents\\Grad_hw\\CSE515\\CSE515_Project\\main.py)"
     ]
    }
   ],
   "source": [
    "#Task 1\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#returns the top-k topics \n",
    "def PCAsetup(wordMat, k):\n",
    "    #calculate PCA\n",
    "    pca = PCA(k)\n",
    "    pc = pca.fit_transform(wordMat)\n",
    "    topK = pd.DataFrame(data = pc)\n",
    "    \n",
    "    return topK\n",
    "\n",
    "def SVD(k):\n",
    "    return topK\n",
    "\n",
    "def NMF(k):\n",
    "    return topK\n",
    "\n",
    "def LDA(k):\n",
    "    return topK\n",
    "\n",
    "\n",
    "def makeMat(vectModel, axis):\n",
    "        \n",
    "    #read files\n",
    "    if vectModel == \"tf\":\n",
    "        Xmat = []\n",
    "        for file in glob.glob(directory + axis + \"/tf_vectors_*.txt\"):\n",
    "            #read tf file\n",
    "            f = open(file, \"r\")\n",
    "            tf_vectors = f.readlines()\n",
    "        \n",
    "            gestWords = []\n",
    "            tfVals = []\n",
    "        \n",
    "            #split the line into the word and tf value\n",
    "            for line in tf_vectors:\n",
    "                noDash = line.split(\"-\")\n",
    "                tf_val = noDash[1]\n",
    "                word = noDash[0].split(\",\")\n",
    "                word[2] = word[2].replace(\")\",\"\")\n",
    "                word[2] = word[2].replace(\"'\", \"\")\n",
    "                word[2] = word[2].replace(\" \", \"\")\n",
    "                tf_val = tf_val.replace(\"\\n\", \"\")\n",
    "                gestWords.append(word[2])\n",
    "                tfVals.append(tf_val)\n",
    "           \n",
    "        \n",
    "            index = 0\n",
    "            startI = \"1\"\n",
    "            for y in range(1, w):\n",
    "                startI = startI + \"1\"\n",
    "            startI = int(startI)\n",
    "        \n",
    "            #create dictionary with every word\n",
    "            numWords = startI * (2*r) - startI\n",
    "            wordMat = []\n",
    "    \n",
    "            for i in range(0, numWords + 1):\n",
    "                wordMat.append(0)\n",
    "            \n",
    "            # put tf values into matrix where column = word\n",
    "            for x in gestWords:\n",
    "                xint = int(x)\n",
    "            \n",
    "                #if wordMat[xint - startI] == 0:\n",
    "                wordMat[xint - startI] = wordMat[xint - startI] + float(tfVals[index])\n",
    "                index = index + 1\n",
    "                \n",
    "            \n",
    "            for iterate in range(0, len(wordMat)):\n",
    "                wordMat[iterate] = wordMat[iterate] / 20\n",
    "\n",
    "            Xmat.append(wordMat)\n",
    "            f.close()\n",
    "           \n",
    "        return Xmat\n",
    "    \n",
    "    elif vectModel == \"idf\":\n",
    "        return wordMat\n",
    "    \n",
    "def task1(gestfiles, vectModel, useOp, k):\n",
    "    \n",
    "    if useOp == \"PCA\":\n",
    "        #PCA for X axis\n",
    "        wordMat = makeMat(vectModel, gestfiles)\n",
    "        topk = PCAsetup(wordMat, k)\n",
    "        print(\"\\nPCA for \" + gestfiles + \" gesture files:\\n\")\n",
    "        print(topk)\n",
    "        \n",
    "    elif useOp == \"SVD\":\n",
    "        topk = SVD(k)\n",
    "    elif useOp == \"NMF\":\n",
    "        topk = NMF(k)\n",
    "    elif useOp == \"LDA\":\n",
    "        topk = LDA(k)\n",
    "\n",
    "\n",
    "gestfiles = input(\"Enter the folder that you want analyzed: \")\n",
    "vectModel = input(\"Enter the vector model: \")\n",
    "k = input(\"Enter k: \")\n",
    "useOp = input(\"Enter the analysis you would like to use: \")\n",
    "k = int(k)\n",
    "task1(gestfiles, vectModel, useOp, k)\n",
    "\n",
    "#sample output: \n",
    "#Enter the folder that you want analyzed: X\n",
    "#Enter the vector model: tf\n",
    "#Enter k: 10\n",
    "#Enter the analysis you would like to use: PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
